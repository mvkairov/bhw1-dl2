{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c605c7",
   "metadata": {
    "cellId": "tybx6jf49lk9gf4kkq62"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059ce908",
   "metadata": {
    "cellId": "8g7dikaaffkfhuth2i7dat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /home/jupyter/.local/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: wandb in /home/jupyter/.local/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /kernel/lib/python3.10/site-packages (from wandb) (5.7.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from wandb) (1.38.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jupyter/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /home/jupyter/.local/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /kernel/lib/python3.10/site-packages (from wandb) (51.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /kernel/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Collecting charset-normalizer~=2.0.0 (from requests<3,>=2.0.0->wandb)\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: charset-normalizer\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "%pip install sentencepiece wandb tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6707d7",
   "metadata": {
    "cellId": "mat8bhd6qygcull3dh3g7o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbhwdl\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/\n",
      "run.ipynb\n",
      "\u001b[01;34mwandb\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "%ls\n",
    "# !git clone https://github.com/mvkairov/bhwdl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b805c6b",
   "metadata": {
    "cellId": "t6w5q4yt8odf7ngukz88l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/bhwdl\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "%cd bhwdl\n",
    "import sys\n",
    "sys.path.append('LLAMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc295773",
   "metadata": {
    "cellId": "r39ncyjujah7v7z88to7uc"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "from LLAMA.tinystories import TSDataset\n",
    "from LLAMA.model import LM\n",
    "from LLAMA.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6236092",
   "metadata": {
    "cellId": "j2vjjz3wehk07lzmx6jvh1t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "train_ds = TSDataset('../data/train.txt')\n",
    "val_ds = TSDataset('../data/val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb9d2b2",
   "metadata": {
    "cellId": "cg0g8qbxsmo8h9p4fwy3oy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717700 27631 15000\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "print(len(train_ds), len(val_ds), train_ds.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85102a81",
   "metadata": {
    "cellId": "glo8f2tv4t411z5sxwgl2uh"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112c6e8b",
   "metadata": {
    "cellId": "mxl9c845jt9429yeplt4w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "import wandb\n",
    "wandb.login(key='67d3c077c0b4327f7734330abc8ede91d268977f', relogin=True)\n",
    "run_i = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895e2c8c",
   "metadata": {
    "cellId": "spj4nkalg4j4c2dujujtvv"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "# !git stash\n",
    "# !git pull https://github.com/mvkairov/bhwdl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf85b78",
   "metadata": {
    "cellId": "wtaao65qq2o7o20o7m754t"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "390613f7",
   "metadata": {
    "cellId": "q0noqdq486qynvdhe1z7cg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36395672 parameters :)\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# run_i = 9\n",
    "model = LM(8, 512, 8, train_ds.vocab_size, 1536, 0.08).to('cuda')\n",
    "model = model.to('cuda')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-4, epochs=32, steps_per_epoch=1500, pct_start=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a9d3db",
   "metadata": {
    "cellId": "a4ij9u0k1jbves77eipmj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmkairov\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jupyter/work/resources/bhwdl/wandb/run-20231216_154757-p153y46j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun_max_10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/mkairov/bhwdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/mkairov/bhwdl/runs/p153y46j\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f4cfa0466843868954a0e1cb5d1529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 150; train_loss 7.646\n",
      "step 300; train_loss 6.571\n",
      "step 450; train_loss 6.041\n",
      "step 600; train_loss 5.695\n",
      "step 750; train_loss 5.438\n",
      "step 900; train_loss 5.234\n",
      "step 1050; train_loss 5.066\n",
      "step 1200; train_loss 4.922\n",
      "step 1350; train_loss 4.797\n",
      "step 1500; train_loss 4.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992a5af6650b477fbb6428eb101bbbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 4.685; val_loss: 3.548\n",
      "['once upon a time, there was a big frog who lived in a nice. the sea, because he drove and the birds all day said, \"you come to have a label know. i want the lake!\"the bird flew and ran together and watched and liked the frog. he would be kind man gave his seeds one day, the little girl smiled. she did not like the little girl named the little girl and said.the girl walked up the special fashion!yes, but she wanted to someone too too late! she did not scared she was dirty at her nose. she played with his lime very happy and play with real spun it was not frightened with the mailman became things. the meaningful. she screamed. had never forgot dressed together all day. new friend and said, and wanted to sing were playing. again felt smart and the flowers awe the cake in any new and her was the smoke. and said, but as she knew that her wings and together. the bird ate it reached the flea and went on it found a bit anything how better adventure the sky and saw the carrot under and started to fold. they clapped. and be time, out of their friends looked happily ever adventures and flew away home, they shared it to the bird in excitement the world time and had made even bow lisa everyone treats and had a gift even about the light. they agreed before. the window. from that clapping important that she in the little grumpy milk toward that if birdhouse for telling don\\'s friends, singing. jumped into the apple thanked his friends was tried and they would be high, and enjoyed the hot. the bird thanked the compromise back knew they hairy to slap amazing the bunny and itself about the puzzle. gently sun lesson that they grabbed the toy. on, they had a magic triangle from that day long time at the monster and shared the'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b4b3617a84ebd89a0a48803e058b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1650; train_loss 3.579\n",
      "step 1800; train_loss 3.528\n",
      "step 1950; train_loss 3.477\n",
      "step 2100; train_loss 3.427\n",
      "step 2250; train_loss 3.377\n",
      "step 2400; train_loss 3.328\n",
      "step 2550; train_loss 3.282\n",
      "step 2700; train_loss 3.237\n",
      "step 2850; train_loss 3.194\n",
      "step 3000; train_loss 3.153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efea6321f3e4ca6b32da14fbfd86898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 3.153; val_loss: 2.647\n",
      "['once upon a time, there was a big forest. in the forest, there was a tornado who liked to see water. one day, the bird saw a big apple. theaste was very bright.the goat was very happy.\"hello, look will be safe,\" said the musician. suddenly, the blueberry happened. plants found some leaf stepped down the carrots to the apple. but when the apple lit, the bee turned into the forest were near.then, the apple stopped crying was empty at everything a giant. it had an sign in its beak. the bee saw the ice roots on its beak! the apple in its beak, and everyone was surprised. started to spoil the ice cream anymore and found a safe. from that day on, the nuts found a small flower home. to the bee flew and wisdom he played with the hive. the giant was happy. they all helped the mushroom treats. was happy that it could find its strong. felt good for a long brown pine. and they became friends and played together every day. the friendly and everyone learned that being kind and even quiet. thaw that day by the shark!from that day on, the storm and even lived in hundred and everyone than. was very happy new forever and the other king knew to stay mis for even the field in the swamp and never bring more new day together,thank his jog and even happier friends known. the forest all happy that his friends, warm, the forest was the zookeeper. wool every day on, the glowing, the team her best friend and the forest was a new friend when flying from that he had helped the talent. when it could have a beautiful mushroom happily ever after.. and friendship her mom. on the shrimp and the fears of the forest was not roar for everyone in the forest, and knew all makes with and the every'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005f56aa00bc482a8b811aad895bd3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3150; train_loss 2.715\n",
      "step 3300; train_loss 2.683\n",
      "step 3450; train_loss 2.654\n",
      "step 3600; train_loss 2.626\n",
      "step 3750; train_loss 2.598\n",
      "step 3900; train_loss 2.570\n",
      "step 4050; train_loss 2.544\n",
      "step 4200; train_loss 2.519\n",
      "step 4350; train_loss 2.495\n",
      "step 4500; train_loss 2.472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0ad8230c644180bc113e2767e11d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 2.472; val_loss: 2.147\n",
      "['tom and his mom were in the garden. they looked at the sky and saw a big yellow hill. \"snake belongs to the top!\" he said. \"it is the view or maybe a will be touched the hill!\" magician\\'s mom said, \"no, let\\'s take some bubbly.\"zip was impatient, but she wanted to take the top of the top of the hill first. tom nodded up and went back to the top of the hill.as they got to the top of the hill, a big mud hit the hill and let him. they pushed the flag up and down the hill. they started the bottom of the hill and soon he bigger.dad and his mom and dad made it dirty with the steps.\"look, tom! it\\'s so the jug\".\",\" say. his dad gasped. \"look, tom. it\\'s so pretty. the hill is very tall and tall. it can\\'t go back. let go up and see how candy sooner it goes and looks out.\"bye,\" ben said. \"how both touch us it?\"johnny and pointed at tom. he nodded and smiled. he ran towards the stone and it ran to safety.\"okay, i\\'m so i\\'m following the one,\" the the sky.\"\"me let us,\" dad said. he looked at his dad said. he couldn\\'t stop sneezing left up and tried to remove. \"phew, mister the damage us,\" least separated always if it means the basket does. just like that says.\"well, it was okays getting closer cookies!\" they are more rare and the hill. they spy again. saw to dad said, and started to him. joe suggested blue crack. he disappeared that they couldn\\'t watch as sam pressed their safely playing with it.\"thank you are important to be careful. they can make sure visitors with brave. they do you think they'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8250cb9da0c493aaa21c7ddfb78b541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4650; train_loss 2.226\n",
      "step 4800; train_loss 2.205\n",
      "step 4950; train_loss 2.190\n",
      "step 5100; train_loss 2.174\n",
      "step 5250; train_loss 2.159\n",
      "step 5400; train_loss 2.144\n",
      "step 5550; train_loss 2.129\n",
      "step 5700; train_loss 2.115\n",
      "step 5850; train_loss 2.102\n",
      "step 6000; train_loss 2.089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24731f193d4345d8a2d16c84ecb8b6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 2.089; val_loss: 1.865\n",
      "['lily and ben are twins. they like to play outside. but today it is gloomy. the sky is gray and it has a flying around. lily and ben are bored. sometimes they want to see the sunset.the sky is clear and bright. it has gray dots on it.\"let\\'s fly it!\" lily says.\"ok, lily, it looks fun. maybe it can go to the sunset!\" ben says. he nods and looks at the sky.they run to the sunset and turn it in the air. they see the sunset and the sunset. they bloom and do not like the sunset. it is hot and bright.\"me too!\" lily cries. \"where are we?\"they learn to do that. \"our, the sunset is very good at together. it is very pretty and peaceful. and sleepy,\" ben says. he points to his mom and hugs them.\"thank you, lily, we are very glad now. stop playing,\" mom says. \"you made some for many things. but, what you do?\"the vine wags \"i got there, mom. please.\"mom smiles and takes them to the sunset. she takes them the sunset. she reaches her hands to try v.\"ready, there is the sunset popping?\" lily says on. \"he looks sour. it looks good!\"ben shakes. \"a scary. this makes funny faces.\"mom is the sunset. a pretty figure more pink. this things us it tastes. the sun, therapist,\" she says ‚Åá  \"we have stars and marshmallows.\"\"very moves, kids you. it likes the sunset still!\" an olives. will say rings like \" taped again another flag to gum?\"\" before it flower do is a twirl to say thank you,\" her. she gives them to dry alone to the stars. but it is slippery.\"mom touched it stone. then, the sky. \"blue ran to both?\" mom.'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8ef426963a4db4ae900055dae653cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6150; train_loss 1.948\n",
      "step 6300; train_loss 1.938\n",
      "step 6450; train_loss 1.928\n",
      "step 6600; train_loss 1.918\n",
      "step 6750; train_loss 1.909\n",
      "step 6900; train_loss 1.900\n",
      "step 7050; train_loss 1.891\n",
      "step 7200; train_loss 1.883\n",
      "step 7350; train_loss 1.875\n",
      "step 7500; train_loss 1.867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6ec3daa8aa4c1c97f3230fd3af58cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.867; val_loss: 1.698\n",
      "['once upon a time, there was a little girl named lily. she loved singing with her cat, fluffy. lily had a camera with a camera. they would take pictures and read it together.one day, lily\\'s mom gave him a camera. she said, \"lily, you have to remember your fun day at school during school today. it\\'s time to write.\" lily was so happy. she knew she loved her attractive pictures.but then, something unexpected happened. when lily woke up, her mom said, \"lily, i got your important invitation. but we must share it with others.\" lily took off her record the camera and began to write. while they said \"rainbow, we have to help others. you are brilliant. i will be one three.\"lily looked up and saw her family her building. they had a fun day became very intelligent and tough experience. lily was not mad at the same picture with her camera, but she knew the camera would say better. she was a good friend. had a fun day at school and couldn\\'t wait for school. made the camera frustrated! went to the boo and put on the camera and held her tightly back. the cafe helped lily relax and her school with their puzzle. everyone was happy. got hurt and could not pay attention the best again.in the end of this day at her funny faces. but just everyone went back to talk! lily knew they would always keep her smile and moving true and felt happy. she had fun at how they made a new friends at night. and enjoyed trying and helped beep when they felt a little in the same time with luna. they played with their simple ideas for the smooth picture. and the thoughtful of her picture had together, sharing their funny. was never turned to\\'s more singing, cozy. true as the day with care of them made'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c560573c2214339a760358e7b690204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7650; train_loss 1.778\n",
      "step 7800; train_loss 1.773\n",
      "step 7950; train_loss 1.767\n",
      "step 8100; train_loss 1.760\n",
      "step 8250; train_loss 1.754\n",
      "step 8400; train_loss 1.749\n",
      "step 8550; train_loss 1.743\n",
      "step 8700; train_loss 1.738\n",
      "step 8850; train_loss 1.733\n",
      "step 9000; train_loss 1.728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3559a73e021468cb52973d6c6454e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.728; val_loss: 1.589\n",
      "['once upon a time, there was a modest pet named becky. she lived in a small house with her family. every day, cari and her family would be together on dust.one day, maxine was making a soft bed wall. nan\\'s family needed to restore their house. she had a big cloth that she could make it neat and strong again. after a few weeks, she went up and down into the bed.now, she did many with the cloth, higher and faster. lou was very happy with her hairy soft bed. she hugged every floor and slowly continued to be flexible by how much they could.\"thank you for teaching me, bongo!\" she said toangles level and they all smiled happily together. at the end of the day, catie was tired but happy she knew to all the fun she could make her family very well. and her family lived happily ever after. and her family in a cozy spot near the window in their small house. loved how patient were working together and always flying away from the safe chair. always remembered her family left the house close with an incredible cuddle and no problem. decided to sleep peacefully for being extra help and enjoy theirtick., thankful for the special family\\'s love and, shoes, only this time it settled inside the bricks from being kind.. and friendships, cher them knew that they could make them new friends who was a happy to help no longer excited just as their happy. eventually and flying the way in the back to make them ride, thankful. and being regular when they need them back and compassionate again.li the little prefer at the chair that\\'s adventures in gloom. tackle in peace paws, but loved had sodaless for the wall back in time together to sleep. closed this birdhouse, knowing her new one for stri this lifeex the colorful ways to produce that she'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892794f0173d43ecac847c1cb370b4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9150; train_loss 1.670\n",
      "step 9300; train_loss 1.666\n",
      "step 9450; train_loss 1.663\n",
      "step 9600; train_loss 1.659\n",
      "step 9750; train_loss 1.655\n",
      "step 9900; train_loss 1.651\n",
      "step 10050; train_loss 1.647\n",
      "step 10200; train_loss 1.644\n",
      "step 10350; train_loss 1.640\n",
      "step 10500; train_loss 1.637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ffa58850e4c86a5408a85fe046ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.637; val_loss: 1.513\n",
      "['once upon a time, there was a furry cat named mark. mark was a happy cat who liked to play with his friends. one day, mark and his friend, a little dog named max, went to play outside.mark said, \"max, look at my new friend max. it is not safe.\" but max did not know that buddy was hiding behind a big tree. he was scared of max. max started to die and go back.suddenly, tim came back from max. when he got frightened, he saw max was very sad. the result was not safe! mark said, \"i know, max! i told him to hide behind the tree. you are safe!\" max said, \"okay, sam, i will punish you!\" and with a twist and he\\'s turn, a big truck came out the door!max was very happy. he grabbed some food from the tree and ran away, feeling safe. the best rain came and fell fast too. mark, max, and his friends laughed all day long. they were happy that they could help each other. from that day on, mark and max buried their big yard to hide and play in the place, always happy., our friends were no longer frightened. needing, they all lived happily ever after time together, soap again. and hopping and over to friends. and playing outside with nothing who encouraged them. having fun and friendship each other. knew that the top was the valley belonged to them had been a gentle, and fun for everyone. from that friendship meant something worth it learned coming back ‚Åá  that take each other was the playtime made them come from him.. friendship each other the marvelous.the moral value of friendship comes from a new friendships. and try to do goal... you make it together, we truly do the strengthcy find the tallest wants to always strokes'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba7497086e641f0b18233c3822efa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10650; train_loss 1.595\n",
      "step 10800; train_loss 1.590\n",
      "step 10950; train_loss 1.588\n",
      "step 11100; train_loss 1.585\n",
      "step 11250; train_loss 1.583\n",
      "step 11400; train_loss 1.581\n",
      "step 11550; train_loss 1.579\n",
      "step 11700; train_loss 1.576\n",
      "step 11850; train_loss 1.574\n",
      "step 12000; train_loss 1.571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c573a5b7e348c1b1755d392cbd8b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.571; val_loss: 1.462\n",
      "['it was sunday morning for the fourth day, but then something was ready. the darkness of the street was wet from the rain.a police officer walked over to the street to see the kids. he looked away and said, \"not yet, i need to rest.\"the police officer was worried. so he came up with a plan. he took a step until the runner made a big stay dry and made a little mark in the street.the police officer smiled with his plan. he said, \"ready, set, go!\" the little boy ran to the nearest box and tried to open it, but it was too tight. the police officer felt a bit scared and said, \"don\\'t worry. i will help you.\" so they worked together, keeping the box safe and warm.finally, after a few minutes, the box closed and the police officer was able to open it.luckily, they were able to catch all the kids he could. from then on, the little boy enjoyed spending time with any ambulance. was always there to help another day. was so excited and eventually knows it was time to see the right journey. nodded as the police officer unpacked their correct phone, happy and brave  ‚Åá  once black, lost your personable is now in the right home!  ‚Åá  everyone will follow him on the rain would be braver and overwhelming ‚Åá  together what an eternity accomplished and alwaysin the day! the car for weeks.ald beamed now, welcomed the little joey had ‚Åá s prayer, and was happy that helped ‚Åá hand! his elderlyated had saved the girl. after days, he didn\\'t seem, eventually was heads down toes, it was held his flashing icy box. hugs him just begun the guitar with eyes twinkled in a smile on his willingness beam, watching his face and he looked down the last to show his microscope and focus'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b961031bfd4603a8aaff9b8eba7840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12150; train_loss 1.546\n",
      "step 12300; train_loss 1.540\n",
      "step 12450; train_loss 1.539\n",
      "step 12600; train_loss 1.537\n",
      "step 12750; train_loss 1.535\n",
      "step 12900; train_loss 1.533\n",
      "step 13050; train_loss 1.531\n",
      "step 13200; train_loss 1.529\n",
      "step 13350; train_loss 1.528\n",
      "step 13500; train_loss 1.526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a5fe4e4d6f4e4ab69865922662e7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.526; val_loss: 1.423\n",
      "['tom and lily were best friends. they liked to play in the park every day. they liked to slide, swing, and run. but they always wanted to slide down. one day, they saw a new boy in the park. his name was max.\"hi, we are tom and lily,\" tom said. \"do you want to slide?\"\"yes, please!\" lily said. \"but we are nice. come on, we will slide together.\"tom and lily went to tom and tried to slide down. they held each other\\'s hands because the slide was dependable. they walked to the slide. they moved their feet on the slide. they felt happy.\"wow, this is amazing!\" tom said. he slid down the slide. he felt like he was flying. lily smiled. they watched lily slide and slide. they got to the slide without getting tired.\"can we play here too?\" lily asked.\"sure, you can,\" tom said. \"we can sit here and play. do you want to read?\"lily nodded. she took their backpacks and sat on the slide. she read some books about animals and places.\"wow, this is fun!\" tom said.\"yes, i have!\" lily said.they were having a frog together.suddenly,. a frog jumped out of the slide and landed on the slide. it was spring. it slid down.lily landed in a little monkey jumped up. she bumped into the prince it. she jumped out of the bars again.\"oh no!\" lily said.\"ow!\" the clown said. \"ah!\" tom said lily. she laughed. \"there, lily. \"why did you jump away!\" tom sat next.\"lily thought you squeal her from under me again,\" lily said mom.the frog jumped out. \"and time stayed up to the jellyfish towels before. lily nodded. she went up to me,\" lily laughed. \"ok,'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008b359b0d624918b8b71d77a85b43ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13650; train_loss 1.505\n",
      "step 13800; train_loss 1.504\n",
      "step 13950; train_loss 1.501\n",
      "step 14100; train_loss 1.499\n",
      "step 14250; train_loss 1.498\n",
      "step 14400; train_loss 1.497\n",
      "step 14550; train_loss 1.495\n",
      "step 14700; train_loss 1.494\n",
      "step 14850; train_loss 1.492\n",
      "step 15000; train_loss 1.490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95615bc0036846228b00d05e0905b693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.490; val_loss: 1.393\n",
      "['tim and sam are brothers. they like to play with their toys and watch videos in the tv. but they do not like to eat dessert after dinner. mom says dessert is good for them. tim and sam do not like cake.one day, mom says they have a surprise for their parents. she tells them they have a new game. there stretches is a big cake with candles and pies on it. it has ice cream on one bar, on top and at the floor. tim and sam love dessert.they eat the cake and play with their toys. they have fun. they do not want to open the candles. they want to see if they can lock the candles. they want to pick up the candles and put them in the freezer like their puppets. they think they can lock the candles on a big chair.they hurry to the bathroom. they run to the door and open it. they see the cake mix very well. they see a big truck in the kitchen. it has wheels and lights and tape. it is dry and shiny. they see a man in the kitchen. he is making pancakes on the cake. he looks sad.tim and sam want to help. they open the doors and windows. they pass and pouring the confetti. they next to the cake and the cake. it is messy. it is ruined. ben\\'s cake. the cake is ruined. he also wants mommy and sam and ben and sam to smell the candles. he looks at the dishes. he felt bad. he can\\'s help ben.\"tim, i don\\'t care. he needs him to be mad at sam. he ismom,\" he says.\"let\\'s be quiet. maybe he does. \\'de ben. he won\\'t stay close the candles. we ruin us. but we will make you very long. he does not want a mess. you,\" tim.tim'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7903046e0e7b43b6b598d26d55a8c84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15150; train_loss 1.469\n",
      "step 15300; train_loss 1.471\n",
      "step 15450; train_loss 1.468\n",
      "step 15600; train_loss 1.468\n",
      "step 15750; train_loss 1.467\n",
      "step 15900; train_loss 1.466\n",
      "step 16050; train_loss 1.465\n",
      "step 16200; train_loss 1.464\n",
      "step 16350; train_loss 1.463\n",
      "step 16500; train_loss 1.462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f21e96140f429b8b0971e6bee05812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.462; val_loss: 1.366\n",
      "[\"once upon a time, there was a little girl named sue. sue loved to scatter her toys in a line. one day, sue found a big ball in the park. she was so happy and excited.sue wanted to give the ball to her friend, tom. sue got a pretty paper and saw each toy. she put a picture on the ball. sue could not wait to give the ball a gift.sue walked to tom's house with the roof. when she got there, she gave the ball to tom. tom was so happy to see the ball. they played with the ball all day long. sue and tom were the best of friends. was very fun and sue was glad to have a new friend to help her. had a friend in sue. they played too, helped each other, and tom used his flexible legs to make the ball go faster. when tom was tired, sue and tom were both happy with their playtime and the big ball. they went home with a big smile, knowing they had a great day together. had a nice day. was a good adventure, and sue was always happy to play with her friend again. went outside too, knowing she had had a great day with her best friend. was watching the world from above her friend and one sharing watching playing with the ball. had a small heart from sue and a vacation for fun day watching hurtful emotion. they promised to always listen to show the day, and they knew recommendations and listen each other.'t need kisses to be kind one another time enjoying being a glowing grown curious. and playing at once more sport for each other hand low past their jokes safe. gifts many friends. happily had such years listened about being triumphant parks came and treats. secretly caught them then. now benjaminsiled went to sleepsince it fell asleep and payoff often won un\"] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7976e5591b0e4daa80af2e307401a292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16650; train_loss 1.446\n",
      "step 16800; train_loss 1.446\n",
      "step 16950; train_loss 1.445\n",
      "step 17100; train_loss 1.443\n",
      "step 17250; train_loss 1.442\n",
      "step 17400; train_loss 1.441\n",
      "step 17550; train_loss 1.441\n",
      "step 17700; train_loss 1.439\n",
      "step 17850; train_loss 1.439\n",
      "step 18000; train_loss 1.438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a5faedc36148c0b13312007b9d96cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.438; val_loss: 1.345\n",
      "[\"once upon a time, there were two friends. they were separate from each other very often.one day, they were playing together. the friends decided to go for a picnic. they were all very patient, it one by one, dreaming of each to come.when they got home, they packed up the things they needed for a picnic. they packed some food, a nice table, and a perfect spot for their picnic!when they were done, they laid board back in the garden and took a beautiful blanket. then they blew out the blanket to themselves and had a picnic the picnic! the friends were so excited and munch on the food that they ate together. it was the best picnic ever! and ig the picnic learned to be patient and wait for the picnic to be more fun.in the end, they were happy that they finally have a picnic at their picnic and it was even more enjoyable! didn't wait to let the picnic get back from their picnic meal. and it was it even more fun! knew that the lunch was going to be easy and fun! friend and the two friends had a nice day full bellies. after a picnic, the two friends had had a great time eating sandwiches. felt so strong and a little three year! first time that they left out and set their love. they all laughed and made it really attractedillas. the lazintntlying projects ready. catching some delicious memories put it into a twentyiar inside, like two activities right next! it helped everyone to enjoy their picnic the park show and saying! everyone had a good fit and was perfect picnic. a celebration friend! they lived a entire wedding! of it was a birthday! plan had just like a grand day nights. they laughed!el that weekend conqueredent of life ‚Åá ing it was great! it was the famous world only they\"] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d7caa9a3043ecaf34e8e1cad4d523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18150; train_loss 1.427\n",
      "step 18300; train_loss 1.427\n",
      "step 18450; train_loss 1.426\n",
      "step 18600; train_loss 1.425\n",
      "step 18750; train_loss 1.423\n",
      "step 18900; train_loss 1.421\n",
      "step 19050; train_loss 1.421\n",
      "step 19200; train_loss 1.420\n",
      "step 19350; train_loss 1.419\n",
      "step 19500; train_loss 1.418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e48789cd5d4fd4954cd42599c30dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.418; val_loss: 1.326\n",
      "['once upon a time, there was a little boy named tim. tim had a big smile on his face when he saw a yellow face. he loved to jump and play with his yellow face all day long.one day, tim was playing with his yellow face when it started to rain. he ran under a tree to soak in the wet mud. mom saw him and said, \"oh no, tim! you are wet! let\\'s go inside and think about how to get dry.\"inside the tree, they saw a small rain drop. tim and his yellow face jumped and splashed in the cold water. the rain made them dry under the tree. they laughed and played until the sun came out. they fell asleep, happy that they didn\\'t jump so far and now had a bright fun day. taught tim a special lesson that day. if he ever needed to jump in a rainstorm without being wet or cold. helped tim make it feel energized again, so he could play in it whenever he had the chance to jump in and play. and spinning together, tim lived happily ever after. his skin was the most important thing they had ever had. means he and his yellow face would be the strongest around. stopped rising,, and finally become more raindrops would appear again for him when needed him to hide..from that day on, tim knew just what had adventures was just as if he jumped in the yellow face\\'d gave him and each day, having a had overcome and love. tim\\'s enormous surprise inside the greenest it was illumin. when he waited, the power after a bright rays he noddedtogether could come back to make so was on to nap his yellow face. yourself again and smell. tim knew it might bring him would always bring him last hand firmly to cover him just like the wind. out soon. while the'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80ccba7560341639945939aa139eb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19650; train_loss 1.403\n",
      "step 19800; train_loss 1.403\n",
      "step 19950; train_loss 1.402\n",
      "step 20100; train_loss 1.402\n",
      "step 20250; train_loss 1.402\n",
      "step 20400; train_loss 1.402\n",
      "step 20550; train_loss 1.401\n",
      "step 20700; train_loss 1.401\n",
      "step 20850; train_loss 1.400\n",
      "step 21000; train_loss 1.400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abe30544f57418aa51c4d6113b7b979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 1.400; val_loss: 1.311\n",
      "['once upon a time, there was a little boy named tim. tim was a very spoiled boy. he always wanted more toys and more books. but, his mom always told him to resist.one day, tim\\'s mom said, \"tim, do not go to the store. the store is for cars to hold.\" tim still did not want to get to play, but he knew he had to listen to his mom. he decided to resist playing upstairs and do some things with the car anyway.at the store, tim came back with his toys and his mom gave him the job. the store was a big bag of toys and games to play with. tim was so happy! he played with the toys and forgot about being a spoiled boy. and from that day on, tim knew that his mom loved him and knew that keeping him safe. tim and his mom enjoyed their time together, and tim was never spoiled again. made the world a better place. in the end, tim and his toys had a great life together.ving museum and tim learned that being mischievous to always listen to his mom and resist encouraging, but it\\'s important to not to resist doing the right ones. tim played happily ever after. and being a is the most popularity of reminding, living inside. and a good the payoff can help others.ulful. tim learned that when someone from his only leads to the things first, thinks it is safe to learn it is important to listen to tim, telling her e next time., hard worker, as important lessons, and respecting you. and caring, about god can enjoy others. was kind and caring without respect so, can good opportunities love, and better after learning and thinks often to share matters, until the fifth happy times about surrendering your kindness. is always remembers bond the foreshadowing is healthier. being considerate'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348465bb144b41ba92ff7fb2590fafc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-60bdf503693e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrun_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/bhwdl/LLAMA/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, pad_idx, optimizer, scheduler, train_loader, val_loader, dataset, wandb_instance, steps_per_epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "wandb.init('bhwdl', name=f'run_max_{run_i}', reinit=True)\n",
    "run_i += 1\n",
    "\n",
    "train(model, 32, train_ds.pad_id, optimizer, scheduler, train_loader, val_loader, train_ds, wandb, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ccd7fd",
   "metadata": {
    "cellId": "44dp39dvi3ck0kk2q4slm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36395672 parameters :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LM(\n",
       "  (embedding): Embedding(15000, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (decoder): Decoder(\n",
       "    (decoder): ModuleList(\n",
       "      (0-7): 8 x DecoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.08, inplace=False)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.08, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.08, inplace=False)\n",
       "        )\n",
       "        (att_lnorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_lnorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=15000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.1\n",
    "model = LM(8, 512, 8, train_ds.vocab_size, 1536, 0.08)\n",
    "check = torch.load('best_model.pt', 'cuda')\n",
    "model.load_state_dict(check)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1330154c",
   "metadata": {
    "cellId": "yf9zgtqxn8fqqd7sny13vk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /home/jupyter/.local/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: dill in /home/jupyter/.local/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /kernel/fallback/lib/python3.10/site-packages (from evaluate) (2.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/jupyter/.local/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from evaluate) (0.19.4)\n",
      "Requirement already satisfied: packaging in /kernel/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /home/jupyter/.local/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jupyter/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Collecting charset-normalizer~=2.0.0 (from requests>=2.19.0->evaluate)\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /kernel/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /kernel/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: charset-normalizer\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e572325e",
   "metadata": {
    "cellId": "ml4rzsrkcrf5bn08rptt5x"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "from LLAMA.train import make_seq\n",
    "\n",
    "ds = val_ds\n",
    "\n",
    "def get_text(prefix, max_len=384):\n",
    "    prefix = ds.text2ids(prefix)\n",
    "    prefix = torch.tensor([[ds.bos_id] + prefix])\n",
    "    prefix = prefix.to('cuda')\n",
    "    texts = make_seq(model, ds.sp_model, 1, ds.pad_id, max_len=max_len, prefix=prefix)\n",
    "    texts = ds.ids2text(texts)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85cf4617",
   "metadata": {
    "cellId": "v2dgo35x8nhp3mk9et54vo"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f23f6f4554cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-e46367c5069d>\u001b[0m in \u001b[0;36mget_text\u001b[0;34m(prefix, max_len)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/bhwdl/LLAMA/model.py\u001b[0m in \u001b[0;36mmake_seq\u001b[0;34m(model, tokenizer, pad_idx, batch_size, prefix, max_len)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_seq_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "prefixes = [\n",
    "    'Tom and Lily were playing with their toys ',\n",
    "    'Lily and Tom were twins who liked to ',\n",
    "    'Emily was very excited. She was going to ',\n",
    "    'One day, a little boy named Tim found a ',\n",
    "    'Once upon a time, there was an octopus named Ollie. Ollie was a '\n",
    "]\n",
    "\n",
    "for p in prefixes:\n",
    "    print(get_text(p), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95c4852e",
   "metadata": {
    "cellId": "5f7o5gjn64si29ci6391rf"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'maybe_sync' from 'fsspec.asyn' (/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-042b0c32e4d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perplexity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"metric\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/evaluate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluation_suite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluationSuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .evaluator import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mAudioClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/evaluate/evaluation_suite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2.15.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBeamBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnaming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_split_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames_for_dataset_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMemoryMappedTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/download/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstreaming_download_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamingDownloadManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOMPRESSION_FILESYSTEMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m from ..utils.file_utils import (\n\u001b[1;32m     23\u001b[0m     \u001b[0mget_authentication_headers_for_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/filesystems/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_has_s3fs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0ms3filesystem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3FileSystem\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m COMPRESSION_FILESYSTEMS: List[compression.BaseCompressedFileFileSystem] = [\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/filesystems/s3filesystem.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0ms3fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/s3fs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3FileSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS3File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3Map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/s3fs/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractBufferedFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfer_storage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsyncFileSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiobotocore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'maybe_sync' from 'fsspec.asyn' (/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py)"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "import evaluate\n",
    "\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "raw_gen = make_seq(model, ds.sp_model, 32, ds.pad_id, max_len=256)\n",
    "texts = ds.ids2text(raw_gen)\n",
    "p = perplexity.compute(model_id='gpt2-xl', add_start_token=False, predictions=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b138716",
   "metadata": {
    "cellId": "7u9qicrot9eplh6urx8ein"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/jupyter/.local/lib/python3.10/site-packages (4.36.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/70/25/fab23259a52ece5670dcb8452e1af34b89e6135ecc17cd4b54b4b479eac6/fsspec-2023.12.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /kernel/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting charset-normalizer~=2.0.0 (from requests->transformers)\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, charset-normalizer\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.10.0\n",
      "    Uninstalling fsspec-2021.10.0:\n",
      "      Successfully uninstalled fsspec-2021.10.0\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.15.0 requires fsspec[http]<=2023.10.0,>=2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12 fsspec-2023.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fsspec==2023.1.0\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "huggingface-hub 0.19.4 requires fsspec>=2023.5.0, but you have fsspec 2023.1.0 which is incompatible.\n",
      "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "\n",
    "# %pip install transformers\n",
    "%pip install fsspec==2023.1.0 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf273684",
   "metadata": {
    "cellId": "e3273omwgaqat69okmhs2o"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'maybe_sync' from 'fsspec.asyn' (/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b5c2abd47f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2-xl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/import_hooks.py\u001b[0m in \u001b[0;36m_exec_module\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mnotify_module_loaded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/evaluate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluation_suite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluationSuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .evaluator import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mAudioClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/evaluate/evaluation_suite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/wandb/sdk/lib/import_hooks.py\u001b[0m in \u001b[0;36m_exec_module\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mnotify_module_loaded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2.15.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBeamBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_download_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgetsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m from .features.features import (\n\u001b[1;32m     30\u001b[0m     \u001b[0mFeatureType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"TranslationVariableLanguages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArray2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArray3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArray4D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArray5D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/audio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_download_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxsplitext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mno_op_if_value_is_null\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_to_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/download/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdownload_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstreaming_download_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamingDownloadManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOMPRESSION_FILESYSTEMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m from ..utils.file_utils import (\n\u001b[1;32m     23\u001b[0m     \u001b[0mget_authentication_headers_for_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/filesystems/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_has_s3fs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0ms3filesystem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3FileSystem\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m COMPRESSION_FILESYSTEMS: List[compression.BaseCompressedFileFileSystem] = [\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/filesystems/s3filesystem.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0ms3fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/s3fs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3FileSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS3File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS3Map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/s3fs/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractBufferedFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfer_storage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsyncFileSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiobotocore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'maybe_sync' from 'fsspec.asyn' (/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py)"
     ]
    }
   ],
   "source": [
    "#!g2.1\n",
    "\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2-xl').cuda()\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "perplexity = load('perplexity', module_type='metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5461297",
   "metadata": {
    "cellId": "vm3dfm9cirj8n0en607b"
   },
   "outputs": [],
   "source": [
    "#!g2.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "cb230409-d96a-453c-bc23-cc7f6194d482",
  "notebookPath": "run.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
