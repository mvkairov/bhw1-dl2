{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tinystories import *\n",
    "from llama import LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TinyStoriesDataset(data_file=\"./archive/TinyStoriesV3-GPT4-train.txt\", sp_model_prefix=\"/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = TinyStoriesDataset(data_file=\"./archive/TinyStoriesV3-GPT4-valid.txt\", sp_model_prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn, pad_idx, device):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for tgt, length in tqdm(dataloader):\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        tgt_mask, tgt_padding_mask = create_mask(tgt_input, pad_idx, device)\n",
    "        logits = model(tgt_input, tgt_mask, tgt_padding_mask)\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(dataloader)\n",
    "\n",
    "\n",
    "def train(n_epochs, model, pad_idx, optimizer, train_loader, val_loader, device, evaluation_step=4000):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        losses = 0\n",
    "\n",
    "        for i, (tgt, length) in tqdm(enumerate(train_loader)):\n",
    "            tgt = tgt.to(device)\n",
    "            tgt_input = tgt[:-1, :]\n",
    "            tgt_mask, tgt_padding_mask = create_mask(tgt_input, pad_idx, device)\n",
    "            logits = model(tgt_input, tgt_mask, tgt_padding_mask)\n",
    "            optimizer.zero_grad()\n",
    "            tgt_out = tgt[1:, :]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "\n",
    "            if i % evaluation_step == 0:\n",
    "                val_loss = evaluate(model, val_loader, loss_fn, pad_idx, device)\n",
    "                print((f\"Epoch: {epoch}, Train loss: {(losses / evaluation_step):.3f}, Val loss: {val_loss:.3f}\"))\n",
    "                losses = 0\n",
    "\n",
    "        val_loss = evaluate(model, val_loader, loss_fn, pad_idx, device)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {(losses / (len(train_loader) % evaluation_step)):.3f}, Val loss: {val_loss:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
